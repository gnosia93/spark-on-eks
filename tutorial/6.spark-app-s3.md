이 실습은 [An Example to Predict Customer Churn with Sparkify](https://towardsdatascience.com/a-tutorial-using-spark-for-big-data-an-example-to-predict-customer-churn-9078ac9a1e85) 를 기반으로 작성되었습니다.


### 1. S3 에 데이터 파일 업로드 ###

```
$ cd; git clone https://github.com/gnosia93/spark-on-eks.git

$ cd spark-on-eks/dataset
```

s3 버킷을 만들고 분석 대상 데이터를 업로드 한다. 
```
$ aws s3api create-bucket --bucket spark-on-eks-`whoami` \
  --region ap-northeast-2 \
  --create-bucket-configuration LocationConstraint=ap-northeast-2

$ aws s3api put-object --bucket spark-on-eks-`whoami` \
  --key raw/mini_sparkify_event_data.json.gz \
  --body mini_sparkify_event_data.json.gz

$ aws s3api list-objects-v2 --bucket spark-on-eks-`whoami`
{
    "Contents": [
        {
            "Key": "raw/mini_sparkify_event_data.json.gz",
            "LastModified": "2023-02-05T01:42:52+00:00",
            "ETag": "\"236aa3bb11ed39f38d7615b3ce709980\"",
            "Size": 10661110,
            "StorageClass": "STANDARD"
        }
    ]
}
```

로컬 PC 다운로드 가능한지 확인한다.
```
```


### 2. 주피터랩을 이용한 Interactive 데이터 전처리 및 피처 엔지니어링 ##### 



### 3. InteliJ로 스파크 어플리케이션 개발하기 ###






##### [참고] S3에 있는 jar 파일로 실행하기 ##### 

* https://itnext.io/things-to-consider-to-submit-spark-jobs-on-kubernetes-766402c21716



## 참고자료 ##
* https://stackoverflow.com/questions/55189673/how-to-add-customized-jar-in-jupyter-notebook-in-scala
* https://github.com/vericast/spylon-kernel/blob/master/examples/basic_example.ipynb    -- spylon_kernel 
* https://jhleeeme.github.io/read-aws-s3-data-on-spark/
* https://github.com/jadianes/spark-py-notebooks
* https://towardsdatascience.com/a-tutorial-using-spark-for-big-data-an-example-to-predict-customer-churn-9078ac9a1e85
* https://github.com/elifinspace/sparkify

