spark-3.3.1-bin-hadoop3 바이너리에 포함되어 있는 SparkPi 라는 어플리케이션을 테스트 해볼 예정이다. 어플리케이션은 스칼라로 구현되 있으며,
examples/jars/spark-examples_2.12-3.3.1.jar 경로에 jar 파일 형태로 패키징 되어 있다.  
로컬 도커, 도커 데스크 탑의 쿠버네티스 및 EKS 클러스터를 이용하여 서로 다른 환경에서 동작여부를 확인 할 예정이다. 

### 1. 로컬 docker 환경에서 실행하기 ###

```
$ cd ; cd spark-3.3.1-bin-hadoop3

$ ./bin/spark-submit \
    --master local \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=public.ecr.aws/o5l1c9o9/spark-scala-container:latest \
    ./examples/jars/spark-examples_2.12-3.3.1.jar

23/02/04 14:25:33 INFO SparkContext: Running Spark version 3.3.1
23/02/04 14:25:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/02/04 14:25:33 INFO ResourceUtils: ==============================================================
23/02/04 14:25:33 INFO ResourceUtils: No custom resources configured for spark.driver.
23/02/04 14:25:33 INFO ResourceUtils: ==============================================================
23/02/04 14:25:33 INFO SparkContext: Submitted application: Spark Pi
23/02/04 14:25:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)

...
...
23/02/04 14:25:36 INFO SparkUI: Stopped Spark web UI at http://192.168.29.29:4040
23/02/04 14:25:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/02/04 14:25:36 INFO MemoryStore: MemoryStore cleared
23/02/04 14:25:36 INFO BlockManager: BlockManager stopped
23/02/04 14:25:36 INFO BlockManagerMaster: BlockManagerMaster stopped
23/02/04 14:25:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/02/04 14:25:36 INFO SparkContext: Successfully stopped SparkContext
23/02/04 14:25:36 INFO ShutdownHookManager: Shutdown hook called
23/02/04 14:25:36 INFO ShutdownHookManager: Deleting directory /private/var/folders/p5/xj5kthtj7qxgwlnsxnt02bjc0000gr/T/spark-661afe02-687c-4710-96b0-b3113b5dbedf
23/02/04 14:25:36 INFO ShutdownHookManager: Deleting directory /private/var/folders/p5/xj5kthtj7qxgwlnsxnt02bjc0000gr/T/spark-5441fbe9-a6cc-45ed-9641-6557c54bdaa5
```

### 2. docker desktop K8S 에서 실행하기 ####

docker-desktop 으로 k8s 컨텍스트를 변경 한 후, 클러스터 API 엔드포인트 정보를 받아온다. 
```
$ kubectl config use-context docker-desktop
Switched to context "docker-desktop".

$ kubectl config get-contexts
CURRENT   NAME                                             CLUSTER                                 AUTHINFO                                         NAMESPACE
*         docker-desktop                                   docker-desktop                          docker-desktop
          name-of-account@spark-on-eks.ap-northeast-2.eksctl.io   spark-on-eks.ap-northeast-2.eksctl.io   name-of-account@spark-on-eks.ap-northeast-2.eksctl.io

$ kubectl cluster-info
Kubernetes control plane is running at https://kubernetes.docker.internal:6443
CoreDNS is running at https://kubernetes.docker.internal:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

서비스 어카운트(spark) 을 생성하고 클러스터 edit 롤을 바인딩 한다.
```
% kubectl create serviceaccount spark
serviceaccount/spark created

$ kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
clusterrolebinding.rbac.authorization.k8s.io/spark-role created
```

spark-submit 시 --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark 파리미터를 사용한다.
어플리케이션 jar 의 경우 도커 이미지 내부에 패키징 되어 있는 관계로, 'local://' 키워드를 이용하여 경로를 설정해 줘야 하며, 이떄 경로는 도커 파일 시스템에서 절대 경로로 설정해야 한다.  
--master 파라미터의 주소값은 위에서 조회된 api 엔드 포인트를 사용한다.

```
$ ./bin/spark-submit \
    --master k8s://https://kubernetes.docker.internal:6443 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=public.ecr.aws/o5l1c9o9/spark-scala-container:latest \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.context=docker-desktop \
    local:///opt/spark/examples/jars/spark-examples_2.12-3.3.1.jar 
    
$ kubectl get pods
NAME                               READY   STATUS      RESTARTS   AGE
spark-pi-1763c6861b9822c2-driver   0/1     Completed   0          49s
```

### 3. EKS 클러스터에서 실행하기 ###

```
$ kubectl config use-context name-of-account@spark-on-eks.ap-northeast-2.eksctl.io
Switched to context "name-of-account@spark-on-eks.ap-northeast-2.eksctl.io".

$ kubectl config get-contexts
CURRENT   NAME                                             CLUSTER                                 AUTHINFO                                         NAMESPACE
          docker-desktop                                   docker-desktop                          docker-desktop
*         name-of-account@spark-on-eks.ap-northeast-2.eksctl.io   spark-on-eks.ap-northeast-2.eksctl.io   name-of-account@spark-on-eks.ap-northeast-2.eksctl.io

$ kubectl cluster-info
Kubernetes control plane is running at https://D90FB9BFE96932CC78C3D6CE23033347.gr7.ap-northeast-2.eks.amazonaws.com
CoreDNS is running at https://D90FB9BFE96932CC78C3D6CE23033347.gr7.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

서비스 어카운트(spark) 을 생성하고 클러스터 edit 롤을 바인딩 한다.
```
$ kubectl create serviceaccount spark
serviceaccount/spark created

$ kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
clusterrolebinding.rbac.authorization.k8s.io/spark-role created
```

```
$ cd ; cd spark-3.3.1-bin-hadoop3

$ ./bin/spark-submit \
    --master k8s://https://D90FB9BFE96932CC78C3D6CE23033347.gr7.ap-northeast-2.eks.amazonaws.com \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=public.ecr.aws/o5l1c9o9/spark-scala-container:latest \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.context=name-of-account@spark-on-eks.ap-northeast-2.eksctl.io  \
    local:///opt/spark/examples/jars/spark-examples_2.12-3.3.1.jar 
    
$ kubectl get pods
NAME                               READY   STATUS      RESTARTS   AGE
spark-pi-b31214861bf0441e-driver   0/1     Completed   0          99s   
 ```


### 4. S3에 있는 jar 파일로 실행하기 ### 

* https://itnext.io/things-to-consider-to-submit-spark-jobs-on-kubernetes-766402c21716



#### [참고] 컨테이너 실행 오류 디버깅 ####

```
$ kubectl get pods
NAME                               READY   STATUS   RESTARTS   AGE
spark-pi-d2fa188616fa86ef-driver   0/1     Error    0          17m

$ kubectl describe pod spark-pi-d2fa188616fa86ef-driver

$ kubectl logs spark-pi-d2fa188616fa86ef-driver
```




## 참고자료 ##
* https://stackoverflow.com/questions/58222205/uber-jar-not-found-in-kubernetes-via-spark-submit
* https://spark.apache.org/docs/latest/running-on-kubernetes.html
* https://spark.apache.org/docs/latest/configuration.html
* https://sparkbyexamples.com/spark/spark-submit-command/
* [[k8s][Error] Arm-AMD CPU 사이 문제 해결 - 파드 생성 시 CrashLoopBackOff, exec user process caused: exec format error 문제
](https://kimjingo.tistory.com/221)
