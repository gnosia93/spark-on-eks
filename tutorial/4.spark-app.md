
### 1. api 서버 URL 확인 ###

```
$ kubectl cluster-info
Kubernetes control plane is running at https://D90FB9BFE96932CC78C3D6CE23033347.gr7.ap-northeast-2.eks.amazonaws.com
CoreDNS is running at https://D90FB9BFE96932CC78C3D6CE23033347.gr7.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

### 2. 테스트 어플리케이션 실행 ###

쿠버네티스 클러스터에서 스파크 어플리케이션을 실행하기 위해 아래와 같이 spark-submit 명령어를 사용한다. 이때 쿠버네티스 api 주소 및 포트는 위에서 조회한 정보로 대체하고, 스파크 컨테이너 이미지의 경우 좀전에 생성한 AWS public ecr 레포지토리의 URL 을 입력한다. 

[템플릿]
```
$ ./bin/spark-submit \
    --master k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=<spark-image> \
    local:///path/to/examples.jar
```

[실제 명령어]
```
$ cd ; cd spark-3.3.1-bin-hadoop3

$ ./bin/spark-submit \
    --master k8s://https://D90FB9BFE96932CC78C3D6CE23033347.gr7.ap-northeast-2.eks.amazonaws.com \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=public.ecr.aws/o5l1c9o9/spark-scala-container:latest \
    local://./examples/jars/spark-examples_2.12-3.3.1.jar
```


## 참고자료 ##

* https://spark.apache.org/docs/latest/running-on-kubernetes.html
* https://spark.apache.org/docs/latest/configuration.html
