### ecr 레포지토리 생성 ###

```
$ aws ecr-public create-repository \
     --repository-name sparky-spark-app \
     --region us-east-1   
{
    "repository": {
        "repositoryArn": "arn:aws:ecr-public::xxxxxxxxxxx:repository/sparky-spark-app",
        "registryId": "xxxxxxxxxxx",
        "repositoryName": "sparky-spark-app",
        "repositoryUri": "public.ecr.aws/o5l1c9o9/sparky-spark-app",
        "createdAt": "2023-02-06T11:07:55.946000+09:00"
    },
    "catalogData": {}
}     
```

### 도커 패키징 하기 ###

[Dockerfile]
```
FROM public.ecr.aws/o5l1c9o9/spark-scala-container:latest
ARG spark_uid=185

USER root 
RUN set -ex && mkdir -p /opt/spark/app

COPY SparkySpark-assembly-0.1.0-SNAPSHOT.jar /opt/spark/app
USER ${spark_uid}
```

spark-on-eks 디렉토리로 이동해서 위에 나와 있는 내용으로 Dockerfile 을 생성하고, AWS_ACCESS_KEY_ID 와 AWS_SECRET_ACCESS_KEY 설정한 후 
이미지를 빌드한다. (보안상 문제가 발생할 수 있다. --> 컨테이너의 환경 변수를 외부에서 조회할 수 가 있을듯 하다??)

```
$ vi Dockerfile


$ aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws

$ cd; mkdir -p spark-on-eks/app; cd spark-on-eks/app

$ cp /Users/soonbeom/IdeaProjects/SparkySpark/target/scala-2.13/SparkySpark-assembly-0.1.0-SNAPSHOT.jar \
  SparkySpark-assembly-0.1.0-SNAPSHOT.jar

$ export AWS_ACCESS_KEY_ID=xxxx
$ export AWS_SECRET_ACCESS_KEY=yyyy

$ docker buildx build --push \
     --platform linux/amd64,linux/arm64 \
     --build-arg access_key=$AWS_ACCESS_KEY_ID,secret_key=$AWS_SECRET_ACCESS_KEY \
     -t public.ecr.aws/o5l1c9o9/sparky-spark-app:latest .
```

### s3 버킷 접근 권한 설정 ###

....

### eks 에서 실행하기 ###

```
$ kubectl config use-context name-of-account@spark-on-eks.ap-northeast-2.eksctl.io
Switched to context "name-of-account@spark-on-eks.ap-northeast-2.eksctl.io".

$ kubectl config get-contexts
CURRENT   NAME                                             CLUSTER                                 AUTHINFO                                         NAMESPACE
          docker-desktop                                   docker-desktop                          docker-desktop
*         name-of-account@spark-on-eks.ap-northeast-2.eksctl.io   spark-on-eks.ap-northeast-2.eksctl.io   name-of-account@spark-on-eks.ap-northeast-2.eksctl.io

$ kubectl cluster-info
Kubernetes control plane is running at https://FC91D79A06A89466662783481F8328C7.gr7.ap-northeast-2.eks.amazonaws.com
CoreDNS is running at https://FC91D79A06A89466662783481F8328C7.gr7.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy


$ cd ; cd spark-3.3.1-bin-hadoop3

$ ./bin/spark-submit \
    --master k8s://https://FC91D79A06A89466662783481F8328C7.gr7.ap-northeast-2.eks.amazonaws.com \
    --deploy-mode cluster \
    --name sparky-spark-app \
    --class SparkySpark \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=public.ecr.aws/o5l1c9o9/sparky-spark-app:latest \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.context=name-of-account@spark-on-eks.ap-northeast-2.eksctl.io  \
    local:////opt/spark/app/SparkySpark-assembly-0.1.0-SNAPSHOT.jar
    
$ kubectl get pods
NAME                               READY   STATUS      RESTARTS   AGE
spark-pi-b31214861bf0441e-driver   0/1     Completed   0          99s   
```

### spark/hadoop -> connect s3 ###
```
* Providing AWS_PROFILE when reading S3 files with Spark - https://stackoverflow.com/questions/67267448/providing-aws-profile-when-reading-s3-files-with-spark

* Get Spark to use your AWS credentials file for S3 - http://wrschneider.github.io/2019/02/02/spark-credentials-file.html

* https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html#Authenticating_with_S3

s3a:// 의 경우 3가지 방식의 인증 체계를 지원한다.

1. acceess_key / screet key 를 파라미터로 넘겨주는 방법
2. fs.s3a.aws.credentials.provider 를 설정하는 방법  (환경 변수 또는 .aws/credential 에서 읽어온다.)
    - EC2 / EKS 등의 경우 서비스 롤을 부여
3. hadoop config 파일에 기록하는 방법.

??? 도커는 어떻게 설정하는 게 맞을까? ---> secret 에 등록 ??? 
```


## 레퍼런스 ##

* [S3 버킷 정책](https://inpa.tistory.com/entry/AWS-%F0%9F%93%9A-S3-%EB%B2%84%ED%82%B7-%EC%83%9D%EC%84%B1-%EC%82%AC%EC%9A%A9%EB%B2%95-%EC%8B%A4%EC%A0%84-%EA%B5%AC%EC%B6%95)
* https://stackoverflow.com/questions/69867171/dockerfile-mkdir-permission-denied
* https://tlsdmstn56.github.io/spark-on-kubernetes/

* [컨피그맵](https://arisu1000.tistory.com/27843)

* [시크릿](https://arisu1000.tistory.com/27844)
