
### ecr 레포지토리 생성 ###

```
$ aws ecr-public create-repository \
     --repository-name sparky-spark-app \
     --region us-east-1   
{
    "repository": {
        "repositoryArn": "arn:aws:ecr-public::xxxxxxxxxxx:repository/sparky-spark-app",
        "registryId": "xxxxxxxxxxx",
        "repositoryName": "sparky-spark-app",
        "repositoryUri": "public.ecr.aws/o5l1c9o9/sparky-spark-app",
        "createdAt": "2023-02-06T11:07:55.946000+09:00"
    },
    "catalogData": {}
}     
```

### 도커 패키징 하기 ###

[Dockerfile]
```
FROM o5l1c9o9/spark-scala-container:latest

RUN set -ex && \
    mkdir -p /opt/spark/app
   
COPY "/Users/soonbeom/IdeaProjects/SparkySpark/target/scala-2.13/SparkySpark-assembly-0.1.0-SNAPSHOT.jar" /opt/spark/app
```

spark-on-eks 디렉토리로 이동해서 위에 나와 있는 내용으로 Dockerfile 을 생성한다.
```
$ cd; mkdir -p spark-on-eks
$ vi Dockerfile
$ "/Users/soonbeom/IdeaProjects/SparkySpark/target/scala-2.13/SparkySpark-assembly-0.1.0-SNAPSHOT.jar" SparkySpark-assembly-0.1.0-SNAPSHOT.jar

$ aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws
```

```
$ docker buildx inspect
$ docker buildx create --use

$ docker buildx build --push \
     --platform linux/amd64,linux/arm64 \
     -t public.ecr.aws/o5l1c9o9/sparky-spark-app:latest .
```


### s3 버킷 접근 권한 설정 ###

....

### eks 에서 실행하기 ###

```
$ kubectl config use-context name-of-account@spark-on-eks.ap-northeast-2.eksctl.io
Switched to context "name-of-account@spark-on-eks.ap-northeast-2.eksctl.io".

$ kubectl config get-contexts
CURRENT   NAME                                             CLUSTER                                 AUTHINFO                                         NAMESPACE
          docker-desktop                                   docker-desktop                          docker-desktop
*         name-of-account@spark-on-eks.ap-northeast-2.eksctl.io   spark-on-eks.ap-northeast-2.eksctl.io   name-of-account@spark-on-eks.ap-northeast-2.eksctl.io

$ kubectl cluster-info
Kubernetes control plane is running at https://FC91D79A06A89466662783481F8328C7.gr7.ap-northeast-2.eks.amazonaws.com
CoreDNS is running at https://FC91D79A06A89466662783481F8328C7.gr7.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy


$ cd ; cd spark-3.3.1-bin-hadoop3

$ ./bin/spark-submit \
    --master k8s://https://FC91D79A06A89466662783481F8328C7.gr7.ap-northeast-2.eks.amazonaws.com \
    --deploy-mode cluster \
    --name sparky-spark-app \
    --class SparkySpark \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=public.ecr.aws/o5l1c9o9/sparky-spark-app:latest \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.context=name-of-account@spark-on-eks.ap-northeast-2.eksctl.io  \
    local:///SparkySpark-assembly-0.1.0-SNAPSHOT.jar
    
$ kubectl get pods
NAME                               READY   STATUS      RESTARTS   AGE
spark-pi-b31214861bf0441e-driver   0/1     Completed   0          99s   
```

## 레퍼런스 ##

* https://tlsdmstn56.github.io/spark-on-kubernetes/

* [컨피그맵](https://arisu1000.tistory.com/27843)

* [시크릿](https://arisu1000.tistory.com/27844)
